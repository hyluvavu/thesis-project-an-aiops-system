{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code is adapted from https://github.com/AXinx/ELBD\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "# Supress warnings for clean output.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.utils.utility import standardizer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import models\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Metrics from Prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metrics(start_time, end_time, step, microservices):\n",
    "    \"\"\"\n",
    "    Fetch metrics for a list of microservices from Prometheus\n",
    "    within a specified time range.\n",
    "    \n",
    "    Parameters:\n",
    "    - start_time: The starting timestamp of the time range\n",
    "    - end_time: The ending timestamp of the time range\n",
    "    - step: Time step granularity of the query (e.g., '5s' for 5 seconds)\n",
    "    - microservices: List of names of the microservices for which metrics are to be fetched\n",
    "    \n",
    "    Returns:\n",
    "    - Dataframe containing the fetched metrics, indexed by timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the Prometheus endpoint.\n",
    "    PROMETHEUS_URL = 'http://localhost:9090/api/v1/query_range'\n",
    "    \n",
    "    fetched_metrics = None\n",
    "\n",
    "    for microservice in microservices:\n",
    "        \n",
    "        # Define the query for the response time.\n",
    "        response_time_query = f\"\"\"\n",
    "        sum(\n",
    "            rate(\n",
    "                istio_request_duration_milliseconds_sum{{\n",
    "                    destination_service_name=\"{microservice}\"\n",
    "                }}[1m]\n",
    "            )\n",
    "        )\n",
    "        /\n",
    "        sum(\n",
    "            rate(\n",
    "                istio_request_duration_milliseconds_count{{\n",
    "                    destination_service_name=\"{microservice}\"\n",
    "                }}[1m]\n",
    "            )\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        # Define the query for the CPU usage in the last minute.\n",
    "        cpu_usage_query = f\"\"\"\n",
    "        sum(\n",
    "            rate(\n",
    "                container_cpu_usage_seconds_total{{\n",
    "                    container=\"{microservice}\"\n",
    "                }}[1m]\n",
    "            )\n",
    "        ) by (pod)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define the query for the total memory usage in bytes.\n",
    "        memory_usage_query = f\"\"\"\n",
    "        sum(\n",
    "            container_memory_working_set_bytes{{\n",
    "                container=\"{microservice}\"\n",
    "            }}\n",
    "        ) by (pod)\n",
    "        \"\"\"\n",
    "\n",
    "        # Define the query for the bytes received over the network\n",
    "        # by the container per second in the last minute.\n",
    "        network_receive_query = f\"\"\"\n",
    "        sum(\n",
    "            rate(\n",
    "                container_network_receive_bytes_total{{\n",
    "                    namespace=\"sock-shop\"\n",
    "                }}[1m]\n",
    "            )\n",
    "            * on(namespace, pod)\n",
    "            group_left(workload)\n",
    "            namespace_workload_pod:kube_pod_owner:relabel{{\n",
    "                namespace=\"sock-shop\",\n",
    "                workload=\"{microservice}\"\n",
    "            }}\n",
    "        ) by (pod)\n",
    "        \"\"\"\n",
    "\n",
    "        # Define the query for the bytes transmitted over the network\n",
    "        # by the container per second in the last minute.\n",
    "        network_transmit_query = f\"\"\"\n",
    "        sum(\n",
    "            rate(\n",
    "                container_network_transmit_packets_total{{\n",
    "                    namespace=\"sock-shop\"\n",
    "                }}[1m])\n",
    "            * on (namespace,pod)\n",
    "            group_left(workload)\n",
    "            namespace_workload_pod:kube_pod_owner:relabel{{\n",
    "                namespace=\"sock-shop\",\n",
    "                workload=\"{microservice}\"\n",
    "            }}\n",
    "        ) by (pod)\n",
    "        \"\"\"\n",
    "        queries = {\n",
    "            'response_time': response_time_query,\n",
    "            'cpu_usage': cpu_usage_query,\n",
    "            'memory_usage': memory_usage_query,\n",
    "            'network_receive': network_receive_query,\n",
    "            'network_transmit': network_transmit_query\n",
    "        }\n",
    "\n",
    "        for metric, query in queries.items():\n",
    "            # Make the API request.\n",
    "            response = requests.get(\n",
    "                PROMETHEUS_URL,\n",
    "                params={\n",
    "                    'query': query,\n",
    "                    'start': start_time,\n",
    "                    'end': end_time,\n",
    "                    'step': step\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Check if the request was successful.\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Convert the data to a dataframe.\n",
    "            data = response.json()['data']['result'][0]['values']\n",
    "            df = pd.DataFrame(data, columns=['timestamp', f'{microservice}_{metric}'])\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "\n",
    "            if fetched_metrics is None:\n",
    "                fetched_metrics = df\n",
    "            else:\n",
    "                fetched_metrics = pd.merge(fetched_metrics, df, on='timestamp', how='outer')\n",
    "    \n",
    "    return fetched_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>carts_response_time</th>\n",
       "      <th>carts_cpu_usage</th>\n",
       "      <th>carts_memory_usage</th>\n",
       "      <th>carts_network_receive</th>\n",
       "      <th>carts_network_transmit</th>\n",
       "      <th>catalogue_response_time</th>\n",
       "      <th>catalogue_cpu_usage</th>\n",
       "      <th>catalogue_memory_usage</th>\n",
       "      <th>catalogue_network_receive</th>\n",
       "      <th>...</th>\n",
       "      <th>shipping_response_time</th>\n",
       "      <th>shipping_cpu_usage</th>\n",
       "      <th>shipping_memory_usage</th>\n",
       "      <th>shipping_network_receive</th>\n",
       "      <th>shipping_network_transmit</th>\n",
       "      <th>user_response_time</th>\n",
       "      <th>user_cpu_usage</th>\n",
       "      <th>user_memory_usage</th>\n",
       "      <th>user_network_receive</th>\n",
       "      <th>user_network_transmit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-09 19:49:38</td>\n",
       "      <td>16.3989605734764</td>\n",
       "      <td>0.21160010944910412</td>\n",
       "      <td>302342144</td>\n",
       "      <td>414579.6051895761</td>\n",
       "      <td>945.7834694105804</td>\n",
       "      <td>14.300608407083766</td>\n",
       "      <td>0.025178680679362957</td>\n",
       "      <td>8425472</td>\n",
       "      <td>149793.32004697676</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5025139664785607</td>\n",
       "      <td>0.0038347791523871116</td>\n",
       "      <td>290775040</td>\n",
       "      <td>5582.620867702063</td>\n",
       "      <td>8.770831165935943</td>\n",
       "      <td>10.192517361114087</td>\n",
       "      <td>0.03585143639003408</td>\n",
       "      <td>13869056</td>\n",
       "      <td>129620.39879716934</td>\n",
       "      <td>264.0533737571409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-09 19:49:43</td>\n",
       "      <td>16.398960573476398</td>\n",
       "      <td>0.21160010944910412</td>\n",
       "      <td>302342144</td>\n",
       "      <td>414579.6051895761</td>\n",
       "      <td>945.7834694105804</td>\n",
       "      <td>13.950413223140496</td>\n",
       "      <td>0.024942260324365747</td>\n",
       "      <td>8425472</td>\n",
       "      <td>146106.34847080632</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5025139664785607</td>\n",
       "      <td>0.0054249188560177184</td>\n",
       "      <td>290766848</td>\n",
       "      <td>7875.2322211488445</td>\n",
       "      <td>12.372742810433232</td>\n",
       "      <td>10.192517361114087</td>\n",
       "      <td>0.03588043955263794</td>\n",
       "      <td>13869056</td>\n",
       "      <td>102480.86666666667</td>\n",
       "      <td>208.76666666666665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09 19:49:48</td>\n",
       "      <td>16.398960573476398</td>\n",
       "      <td>0.21160010944910412</td>\n",
       "      <td>302342144</td>\n",
       "      <td>414579.6051895761</td>\n",
       "      <td>945.7834694105804</td>\n",
       "      <td>13.950413223140496</td>\n",
       "      <td>0.024942260324365747</td>\n",
       "      <td>8425472</td>\n",
       "      <td>146106.3484708063</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5025139664785607</td>\n",
       "      <td>0.0054249188560177184</td>\n",
       "      <td>290766848</td>\n",
       "      <td>7875.2322211488445</td>\n",
       "      <td>12.372742810433232</td>\n",
       "      <td>10.342884415134797</td>\n",
       "      <td>0.03196109325481956</td>\n",
       "      <td>13869056</td>\n",
       "      <td>124792.0142530985</td>\n",
       "      <td>254.2173352902805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-09 19:49:53</td>\n",
       "      <td>16.398960573476398</td>\n",
       "      <td>0.21160010944910412</td>\n",
       "      <td>302342144</td>\n",
       "      <td>414159.84208418365</td>\n",
       "      <td>944.9392558121793</td>\n",
       "      <td>13.950413223140496</td>\n",
       "      <td>0.024942260324365747</td>\n",
       "      <td>8425472</td>\n",
       "      <td>146106.3484708063</td>\n",
       "      <td>...</td>\n",
       "      <td>2.463407821227164</td>\n",
       "      <td>0.0054249188560177184</td>\n",
       "      <td>290766848</td>\n",
       "      <td>7875.2322211488445</td>\n",
       "      <td>12.372742810433232</td>\n",
       "      <td>10.342884415134797</td>\n",
       "      <td>0.028041746957001176</td>\n",
       "      <td>13869056</td>\n",
       "      <td>109598.85961473838</td>\n",
       "      <td>223.26693105220502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-09 19:49:58</td>\n",
       "      <td>15.922145915083965</td>\n",
       "      <td>0.21160010944910412</td>\n",
       "      <td>302342144</td>\n",
       "      <td>414159.84208418365</td>\n",
       "      <td>944.9392558121793</td>\n",
       "      <td>13.950413223140496</td>\n",
       "      <td>0.024942260324365747</td>\n",
       "      <td>8425472</td>\n",
       "      <td>146106.3484708063</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571428571429531</td>\n",
       "      <td>0.0054249188560177184</td>\n",
       "      <td>290766848</td>\n",
       "      <td>7875.2322211488445</td>\n",
       "      <td>12.372742810433232</td>\n",
       "      <td>10.381783615624563</td>\n",
       "      <td>0.024122400659182794</td>\n",
       "      <td>13869056</td>\n",
       "      <td>94405.70497637827</td>\n",
       "      <td>192.3165268141296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>2023-10-09 20:49:18</td>\n",
       "      <td>12.412016908206637</td>\n",
       "      <td>0.06735775734203836</td>\n",
       "      <td>303169536</td>\n",
       "      <td>111112.26866635462</td>\n",
       "      <td>253.9356138617294</td>\n",
       "      <td>9.983564493746268</td>\n",
       "      <td>0.009041210863816242</td>\n",
       "      <td>8478720</td>\n",
       "      <td>63505.083346235224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.192857142856415</td>\n",
       "      <td>0.0029833698639694173</td>\n",
       "      <td>290779136</td>\n",
       "      <td>4304.402584601905</td>\n",
       "      <td>7.912605410141277</td>\n",
       "      <td>7.8989930286712084</td>\n",
       "      <td>0.01776539025582062</td>\n",
       "      <td>14036992</td>\n",
       "      <td>78870.75868621064</td>\n",
       "      <td>160.93241042345278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2023-10-09 20:49:23</td>\n",
       "      <td>12.412016908206637</td>\n",
       "      <td>0.049474834082371695</td>\n",
       "      <td>303169536</td>\n",
       "      <td>97153.09021132377</td>\n",
       "      <td>222.03335326953749</td>\n",
       "      <td>9.983564493746268</td>\n",
       "      <td>0.009041210863816242</td>\n",
       "      <td>8478720</td>\n",
       "      <td>63505.083346235224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2826271186433775</td>\n",
       "      <td>0.0029833698639694173</td>\n",
       "      <td>290779136</td>\n",
       "      <td>4304.402584601905</td>\n",
       "      <td>7.912605410141277</td>\n",
       "      <td>7.898993028671208</td>\n",
       "      <td>0.01776539025582062</td>\n",
       "      <td>14036992</td>\n",
       "      <td>78870.75868621064</td>\n",
       "      <td>160.93241042345278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2023-10-09 20:49:28</td>\n",
       "      <td>11.639807201585533</td>\n",
       "      <td>0.11515058042472587</td>\n",
       "      <td>303202304</td>\n",
       "      <td>83193.9117562929</td>\n",
       "      <td>190.13109267734555</td>\n",
       "      <td>9.983564493746268</td>\n",
       "      <td>0.009041210863816242</td>\n",
       "      <td>8478720</td>\n",
       "      <td>63505.083346235224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.428832116788746</td>\n",
       "      <td>0.0029833698639694173</td>\n",
       "      <td>290779136</td>\n",
       "      <td>4304.402584601905</td>\n",
       "      <td>7.912605410141277</td>\n",
       "      <td>7.659384273005046</td>\n",
       "      <td>0.01776539025582062</td>\n",
       "      <td>14036992</td>\n",
       "      <td>78870.75868621064</td>\n",
       "      <td>160.93241042345278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2023-10-09 20:49:33</td>\n",
       "      <td>12.465076174351715</td>\n",
       "      <td>0.15554773077333703</td>\n",
       "      <td>303202304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.634080717502153</td>\n",
       "      <td>0.009041210863816242</td>\n",
       "      <td>8478720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.428832116788746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290779136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.697896698611778</td>\n",
       "      <td>0.01776539025582062</td>\n",
       "      <td>14036992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2023-10-09 20:49:38</td>\n",
       "      <td>12.465076174351715</td>\n",
       "      <td>0.15554773077333703</td>\n",
       "      <td>303202304</td>\n",
       "      <td>307740.28317899577</td>\n",
       "      <td>708.3986850869089</td>\n",
       "      <td>11.634080717502153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8478720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.428832116788746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290779136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.697896698611778</td>\n",
       "      <td>0.043166532339313</td>\n",
       "      <td>14049280</td>\n",
       "      <td>164724.36117643953</td>\n",
       "      <td>334.1172740004757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp carts_response_time       carts_cpu_usage  \\\n",
       "0   2023-10-09 19:49:38    16.3989605734764   0.21160010944910412   \n",
       "1   2023-10-09 19:49:43  16.398960573476398   0.21160010944910412   \n",
       "2   2023-10-09 19:49:48  16.398960573476398   0.21160010944910412   \n",
       "3   2023-10-09 19:49:53  16.398960573476398   0.21160010944910412   \n",
       "4   2023-10-09 19:49:58  15.922145915083965   0.21160010944910412   \n",
       "..                  ...                 ...                   ...   \n",
       "716 2023-10-09 20:49:18  12.412016908206637   0.06735775734203836   \n",
       "717 2023-10-09 20:49:23  12.412016908206637  0.049474834082371695   \n",
       "718 2023-10-09 20:49:28  11.639807201585533   0.11515058042472587   \n",
       "719 2023-10-09 20:49:33  12.465076174351715   0.15554773077333703   \n",
       "720 2023-10-09 20:49:38  12.465076174351715   0.15554773077333703   \n",
       "\n",
       "    carts_memory_usage carts_network_receive carts_network_transmit  \\\n",
       "0            302342144     414579.6051895761      945.7834694105804   \n",
       "1            302342144     414579.6051895761      945.7834694105804   \n",
       "2            302342144     414579.6051895761      945.7834694105804   \n",
       "3            302342144    414159.84208418365      944.9392558121793   \n",
       "4            302342144    414159.84208418365      944.9392558121793   \n",
       "..                 ...                   ...                    ...   \n",
       "716          303169536    111112.26866635462      253.9356138617294   \n",
       "717          303169536     97153.09021132377     222.03335326953749   \n",
       "718          303202304      83193.9117562929     190.13109267734555   \n",
       "719          303202304                   NaN                    NaN   \n",
       "720          303202304    307740.28317899577      708.3986850869089   \n",
       "\n",
       "    catalogue_response_time   catalogue_cpu_usage catalogue_memory_usage  \\\n",
       "0        14.300608407083766  0.025178680679362957                8425472   \n",
       "1        13.950413223140496  0.024942260324365747                8425472   \n",
       "2        13.950413223140496  0.024942260324365747                8425472   \n",
       "3        13.950413223140496  0.024942260324365747                8425472   \n",
       "4        13.950413223140496  0.024942260324365747                8425472   \n",
       "..                      ...                   ...                    ...   \n",
       "716       9.983564493746268  0.009041210863816242                8478720   \n",
       "717       9.983564493746268  0.009041210863816242                8478720   \n",
       "718       9.983564493746268  0.009041210863816242                8478720   \n",
       "719      11.634080717502153  0.009041210863816242                8478720   \n",
       "720      11.634080717502153                   NaN                8478720   \n",
       "\n",
       "    catalogue_network_receive  ... shipping_response_time  \\\n",
       "0          149793.32004697676  ...     2.5025139664785607   \n",
       "1          146106.34847080632  ...     2.5025139664785607   \n",
       "2           146106.3484708063  ...     2.5025139664785607   \n",
       "3           146106.3484708063  ...      2.463407821227164   \n",
       "4           146106.3484708063  ...      2.571428571429531   \n",
       "..                        ...  ...                    ...   \n",
       "716        63505.083346235224  ...      2.192857142856415   \n",
       "717        63505.083346235224  ...     2.2826271186433775   \n",
       "718        63505.083346235224  ...      2.428832116788746   \n",
       "719                       NaN  ...      2.428832116788746   \n",
       "720                       NaN  ...      2.428832116788746   \n",
       "\n",
       "        shipping_cpu_usage shipping_memory_usage shipping_network_receive  \\\n",
       "0    0.0038347791523871116             290775040        5582.620867702063   \n",
       "1    0.0054249188560177184             290766848       7875.2322211488445   \n",
       "2    0.0054249188560177184             290766848       7875.2322211488445   \n",
       "3    0.0054249188560177184             290766848       7875.2322211488445   \n",
       "4    0.0054249188560177184             290766848       7875.2322211488445   \n",
       "..                     ...                   ...                      ...   \n",
       "716  0.0029833698639694173             290779136        4304.402584601905   \n",
       "717  0.0029833698639694173             290779136        4304.402584601905   \n",
       "718  0.0029833698639694173             290779136        4304.402584601905   \n",
       "719                    NaN             290779136                      NaN   \n",
       "720                    NaN             290779136                      NaN   \n",
       "\n",
       "    shipping_network_transmit  user_response_time        user_cpu_usage  \\\n",
       "0           8.770831165935943  10.192517361114087   0.03585143639003408   \n",
       "1          12.372742810433232  10.192517361114087   0.03588043955263794   \n",
       "2          12.372742810433232  10.342884415134797   0.03196109325481956   \n",
       "3          12.372742810433232  10.342884415134797  0.028041746957001176   \n",
       "4          12.372742810433232  10.381783615624563  0.024122400659182794   \n",
       "..                        ...                 ...                   ...   \n",
       "716         7.912605410141277  7.8989930286712084   0.01776539025582062   \n",
       "717         7.912605410141277   7.898993028671208   0.01776539025582062   \n",
       "718         7.912605410141277   7.659384273005046   0.01776539025582062   \n",
       "719                       NaN   8.697896698611778   0.01776539025582062   \n",
       "720                       NaN   8.697896698611778     0.043166532339313   \n",
       "\n",
       "    user_memory_usage user_network_receive user_network_transmit  \n",
       "0            13869056   129620.39879716934     264.0533737571409  \n",
       "1            13869056   102480.86666666667    208.76666666666665  \n",
       "2            13869056    124792.0142530985     254.2173352902805  \n",
       "3            13869056   109598.85961473838    223.26693105220502  \n",
       "4            13869056    94405.70497637827     192.3165268141296  \n",
       "..                ...                  ...                   ...  \n",
       "716          14036992    78870.75868621064    160.93241042345278  \n",
       "717          14036992    78870.75868621064    160.93241042345278  \n",
       "718          14036992    78870.75868621064    160.93241042345278  \n",
       "719          14036992                  NaN                   NaN  \n",
       "720          14049280   164724.36117643953     334.1172740004757  \n",
       "\n",
       "[721 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start_time = '2023-09-28T13:25:00Z'\n",
    "# end_time = '2023-09-28T14:25:00Z'\n",
    "\n",
    "# Get the current UTC time.\n",
    "current_time = datetime.utcnow()\n",
    "\n",
    "# Subtract 1 hour to get the starting time.\n",
    "one_hour_ago = current_time - timedelta(hours=1)\n",
    "\n",
    "# Format start_time and end_time as strings.\n",
    "start_time = one_hour_ago.strftime('%Y-%m-%dT%H:%M:%S') + 'Z'\n",
    "end_time = current_time.strftime('%Y-%m-%dT%H:%M:%S') + 'Z'\n",
    "\n",
    "step = '5s'\n",
    "microservices = ['carts', 'catalogue', 'front-end', 'orders', 'payment', 'shipping', 'user']\n",
    "\n",
    "fetched_metrics = fetch_metrics(start_time, end_time, step, microservices)\n",
    "fetched_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetched_metrics.to_pickle('online_data_1h.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetched_metrics = pd.read_pickle('online_data_1h.pkl')\n",
    "# fetched_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'carts_response_time', 'carts_cpu_usage',\n",
       "       'carts_memory_usage', 'carts_network_receive', 'carts_network_transmit',\n",
       "       'catalogue_response_time', 'catalogue_cpu_usage',\n",
       "       'catalogue_memory_usage', 'catalogue_network_receive',\n",
       "       'catalogue_network_transmit', 'front-end_response_time',\n",
       "       'front-end_cpu_usage', 'front-end_memory_usage',\n",
       "       'front-end_network_receive', 'front-end_network_transmit',\n",
       "       'orders_response_time', 'orders_cpu_usage', 'orders_memory_usage',\n",
       "       'orders_network_receive', 'orders_network_transmit',\n",
       "       'payment_response_time', 'payment_cpu_usage', 'payment_memory_usage',\n",
       "       'payment_network_receive', 'payment_network_transmit',\n",
       "       'shipping_response_time', 'shipping_cpu_usage', 'shipping_memory_usage',\n",
       "       'shipping_network_receive', 'shipping_network_transmit',\n",
       "       'user_response_time', 'user_cpu_usage', 'user_memory_usage',\n",
       "       'user_network_receive', 'user_network_transmit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetched_metrics.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the Data, Load the Model, and Detect Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    \"\"\"\n",
    "    Normalize the metrics data using Min-Max scaling.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: Dataframe containing the metrics data,\n",
    "    where the first column is 'timestamp'\n",
    "    \n",
    "    Returns:\n",
    "    - Dataframe containing the normalized metrics data,\n",
    "    maintaining the original timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data_temp = pd.DataFrame(scaler.fit_transform(data.drop(['timestamp'], axis=1)))\n",
    "    normalized_data_temp.columns = data.columns[1:]\n",
    "    normalized_data = pd.merge(data.timestamp, normalized_data_temp, left_index=True, right_index=True, how='left')\n",
    "    normalized_data.fillna(method='ffill', inplace=True)  # Forward fill.\n",
    "    normalized_data.fillna(method='bfill', inplace=True)  # Backward fill any remaining NaNs.\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_base_model_scores(normalized_data):\n",
    "    \"\"\"\n",
    "    Generate decision scores for anomalies using base models.\n",
    "    \n",
    "    Parameters:\n",
    "    - normalized_data: Dataframe containing normalized metrics data\n",
    "    \n",
    "    Returns:\n",
    "    - 2D Numpy array containing the decision scores for each base model\n",
    "    \"\"\"\n",
    "\n",
    "    input_data = normalized_data.iloc[:, 1:]\n",
    "    scores = []\n",
    "    \n",
    "    random_state = np.random.RandomState(42)\n",
    "    classifiers = {\n",
    "            'Isolation Forest': IForest(random_state=random_state),\n",
    "            'K Nearest Neighbors (KNN)': KNN(),\n",
    "            'Local Outlier Factor (LOF)': LOF(),\n",
    "            'One-class SVM (OCSVM)': OCSVM()\n",
    "    }\n",
    "    \n",
    "    for _, clf in classifiers.items():\n",
    "        clf.fit(input_data)\n",
    "        decision_scores = clf.decision_function(input_data)\n",
    "        scores.append(decision_scores)\n",
    "\n",
    "    base_model_scores = np.column_stack(scores)\n",
    "    \n",
    "    return base_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(fetched_metrics):\n",
    "    \"\"\"\n",
    "    Detect anomalies in fetched metrics\n",
    "    using an ensemble of base models and a pre-trained MLP.\n",
    "    \n",
    "    Parameters:\n",
    "    - fetched_metrics: Dataframe containing the fetched metrics\n",
    "    \n",
    "    Returns:\n",
    "    - List of predicted labels (1 for anomaly, 0 for normal)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the pre-trained model.\n",
    "    model = models.load_model('pre-trained_ELBD.keras')\n",
    "    model.summary()\n",
    "    \n",
    "    normalized_data = normalize_data(fetched_metrics)\n",
    "    \n",
    "    # Generate decision scores from base models.\n",
    "    base_model_scores = generate_base_model_scores(normalized_data)\n",
    "    \n",
    "    # Standardize the decision scores.\n",
    "    standardized_scores = standardizer(base_model_scores)\n",
    "    \n",
    "    # Predict using ensemble MLP.\n",
    "    predictions = model.predict(standardized_scores)\n",
    "    pred_labels = [1 if p[0] > 0.5 else 0 for p in predictions]\n",
    "    \n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 756, 4)            20        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 756, 20)           100       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 756, 20)           420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 756, 1)            21        \n",
      "=================================================================\n",
      "Total params: 561\n",
      "Trainable params: 561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 756, 4) for input KerasTensor(type_spec=TensorSpec(shape=(None, 756, 4), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 4).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = detect_anomalies(fetched_metrics)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721\n",
      "283\n",
      "438\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_labels))\n",
    "print(pred_labels.count(1))\n",
    "print(pred_labels.count(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_anomalies(fetched_metrics, pred_labels, window_size=60, anomaly_threshold=24):\n",
    "    \"\"\"\n",
    "    Group anomalies based on the number of anomalies in the sliding window.\n",
    "\n",
    "    Parameters:\n",
    "    - fetched_metrics: Dataframe containing the fetched metrics\n",
    "    - pred_labels: List of predicted labels\n",
    "    - window_size: Size of the window \n",
    "    (e.g., for 5 minutes with 5s step, window_size would be 60)\n",
    "    - anomaly_threshold: Minimum number of anomalies in the window\n",
    "    to consider it an anomaly\n",
    "\n",
    "    Returns:\n",
    "    - List of (start, end) timestamp pairs indicating anomalies\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert pred_labels to a dataframe.\n",
    "    pred_labels_df = pd.DataFrame(pred_labels, columns=['pred_label'])\n",
    "    # Associate timestamps from fetched_metrics with pred_labels.\n",
    "    result_df = pd.concat([fetched_metrics['timestamp'], pred_labels_df], axis=1)\n",
    "\n",
    "    anomalies = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(result_df):\n",
    "        window = result_df.iloc[i:i+window_size]\n",
    "        if window['pred_label'].sum() >= anomaly_threshold:\n",
    "            start_timestamp = window.iloc[0]['timestamp']\n",
    "            end_timestamp = window.iloc[-1]['timestamp']\n",
    "            anomalies.append((start_timestamp, end_timestamp))\n",
    "            i += window_size  # Move the window forward by its size.\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Timestamp('2023-10-09 19:49:38'), Timestamp('2023-10-09 19:54:33')),\n",
       " (Timestamp('2023-10-09 19:54:38'), Timestamp('2023-10-09 19:59:33')),\n",
       " (Timestamp('2023-10-09 20:01:18'), Timestamp('2023-10-09 20:06:13')),\n",
       " (Timestamp('2023-10-09 20:30:03'), Timestamp('2023-10-09 20:34:58')),\n",
       " (Timestamp('2023-10-09 20:40:03'), Timestamp('2023-10-09 20:44:58')),\n",
       " (Timestamp('2023-10-09 20:45:03'), Timestamp('2023-10-09 20:49:38'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies = group_anomalies(fetched_metrics, pred_labels)\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inform CausalRCA of the Detected Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inform_causalrca(anomalies):\n",
    "    \"\"\"\n",
    "    Inform CausalRCA to fetch the metrics data for multiple anomalies\n",
    "    and to start performing root cause analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - anomalies: A list of tuples,\n",
    "    each containing a start and end timestamp for an anomaly\n",
    "    \"\"\"\n",
    "    \n",
    "    # CausalRCA API endpoint URL\n",
    "    CAUSALRCA_API_URL = 'http://127.0.0.1:5000/'\n",
    "\n",
    "    if anomalies == []:\n",
    "        data = {'rca_query_ranges': []}\n",
    "    else:\n",
    "        # Convert the list of Timestamp objects to a list of ISO format strings,\n",
    "        # so that it is JSON serializable.\n",
    "        rca_query_ranges_iso = [\n",
    "            {'start_time': start.isoformat(), 'end_time': (start + pd.Timedelta(minutes=5)).isoformat()}\n",
    "            for start, end in anomalies\n",
    "        ]\n",
    "\n",
    "        # Payload data to be sent to CausalRCA\n",
    "        data = {'rca_query_ranges': rca_query_ranges_iso}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(CAUSALRCA_API_URL, json=data)\n",
    "        \n",
    "        # Handle response.\n",
    "        if response.status_code == 200:\n",
    "            print(f'Informed CausalRCA successfully!')\n",
    "            print(f'Response from CausalRCA: {response.text}')\n",
    "        else:\n",
    "            print(f'Failed to inform CausalRCA. Status code: {response.status_code}. Response text: {response.text}')\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f'Error occurred while informing CausalRCA: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to inform CausalRCA. Status code: 500. Response text: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inform_causalrca(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the Results of ELBD to InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_influxdb(fetched_metrics, pred_labels):\n",
    "    \"\"\"\n",
    "    Write prediction results to InfluxDB.\n",
    "\n",
    "    Parameters:\n",
    "    - fetched_metrics: Dataframe containing the fetched metrics\n",
    "    - pred_labels: List of predicted labels (1 for anomaly, 0 for normal)\n",
    "    \"\"\"\n",
    "    \n",
    "    # URL of the InfluxDB instance\n",
    "    URL = 'http://localhost:8086'\n",
    "    # InfluxDB operator API token created when setting up InfluxDB\n",
    "    TOKEN = '8VOesz5g8IG5FMKoaa9gycfFUuANahDHYTqe5-bV-bCKfdCk9tf5Hfge5RxisvM4E1XBTSsJbcMeVcEjsPd8tw=='\n",
    "    ORG = 'influxdata'\n",
    "    BUCKET = 'ELBD'\n",
    "\n",
    "    try:\n",
    "        # Initialize a client.\n",
    "        client = InfluxDBClient(url=URL, token=TOKEN, org=ORG)\n",
    "        write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "        for index, value in enumerate(pred_labels):\n",
    "            # Convert pandas Timestamp to datetime object.\n",
    "            dt_obj = fetched_metrics.timestamp[index].to_pydatetime()\n",
    "\n",
    "            data_point = Point('elbd_results') \\\n",
    "                .time(dt_obj) \\\n",
    "                .field('anomaly', int(value))  # 1 for anomaly, 0 for normal\n",
    "            write_api.write(bucket=BUCKET, org=ORG, record=data_point)\n",
    "\n",
    "        print('Results written to InfluxDB successfully!')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "    \n",
    "    finally:\n",
    "        # Close the client.\n",
    "        client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to InfluxDB successfully!\n"
     ]
    }
   ],
   "source": [
    "write_to_influxdb(fetched_metrics, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
